{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Constants and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "CONNECTION_URI = 'postgresql://metal:test@localhost:5430/metal_db'\n",
    "\n",
    "WEEKDAYS = dict(\n",
    "    zip(range(0,7), [\"Monday\", \"Tuesday\", \"Wednusday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])\n",
    ")\n",
    "\n",
    "MONTH_NAME = dict(\n",
    "    zip(range(1,13), [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"])\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Experement data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = pd.read_csv(\"experement_data/gold_data.csv\")\n",
    "calendar = pd.read_csv(\"data/calendar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Open', 'High', 'Low', 'Close*', 'Adj Close**', 'Volume'], dtype='object')\n",
      "Index(['Date', 'Day', 'Name', 'Type', 'Year'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(exp_data.columns)\n",
    "print(calendar.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Calendar 2000-2020\n",
    " - [Y] Date\n",
    " - [Y] Month, Year, Day\n",
    " - [Y] Day of week, Name of day\n",
    " - [Y] First Day of (month, week, quarter)\n",
    " - [Y] Last Day of (month, week, quarter)\n",
    " - [N] Week of month\n",
    " - [Y] Calendar week\n",
    " - [Y] Early(1-10)/Mid(11-22)/End(>22) Month\n",
    " - [N] Next Day is weekend or holiday\n",
    " - [N] Previous Day is weekend or holiday\n",
    " - [N] LongWeekend start\n",
    " - [N] LongWeekend end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(year=2000, month=1, day=1)\n",
    "step_size = 1\n",
    "end_date = datetime.now()\n",
    "calendar_dataset = defaultdict(list)\n",
    "\n",
    "while start_date<=end_date:\n",
    "    calendar_dataset[\"Date\"].append(start_date.date())\n",
    "    calendar_dataset[\"month\"].append(start_date.month)\n",
    "    calendar_dataset[\"year\"].append(start_date.year)\n",
    "    calendar_dataset[\"day\"].append(start_date.day)\n",
    "    calendar_dataset[\"monthName\"].append(MONTH_NAME[start_date.month])\n",
    "    calendar_dataset[\"dayName\"].append(WEEKDAYS[start_date.weekday()])\n",
    "    calendar_dataset[\"weekend\"].append(True if start_date.weekday()>=5 else None)\n",
    "    calendar_dataset[\"firstDayOfWeek\"].append(True if start_date.weekday()==0 else None)\n",
    "    calendar_dataset[\"lastDayOfWeek\"].append(True if (start_date+timedelta(days=1)).weekday()==0 else None)\n",
    "    if start_date.day <=10: calendar_dataset[\"timeOfMonth\"].append(\"Early\")\n",
    "    elif start_date.day <=22: calendar_dataset[\"timeOfMonth\"].append(\"Mid\")\n",
    "    else : calendar_dataset[\"timeOfMonth\"].append(\"Late\")\n",
    "\n",
    "    start_date+=timedelta(days=step_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_calendar_df = pd.DataFrame(calendar_dataset)\n",
    "full_calendar_df[\"pdDate\"] = full_calendar_df.Date.apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_calendar_df[\"daysInMonth\"] = full_calendar_df.pdDate.apply(lambda x: x.days_in_month)\n",
    "full_calendar_df[\"isLeapYear\"] = full_calendar_df.pdDate.apply(lambda x: x.is_leap_year)\n",
    "full_calendar_df[\"isMonthEnd\"] = full_calendar_df.pdDate.apply(lambda x: x.is_month_end)\n",
    "full_calendar_df[\"isMonthStart\"] = full_calendar_df.pdDate.apply(lambda x: x.is_month_start)\n",
    "full_calendar_df[\"quarter\"] = full_calendar_df.pdDate.apply(lambda x: x.quarter)\n",
    "full_calendar_df[\"isQuarterEnd\"] = full_calendar_df.pdDate.apply(lambda x: x.is_quarter_end)\n",
    "full_calendar_df[\"isQuarterStart\"] = full_calendar_df.pdDate.apply(lambda x: x.is_quarter_start)\n",
    "full_calendar_df[\"isYearStart\"] = full_calendar_df.pdDate.apply(lambda x: x.is_year_start)\n",
    "full_calendar_df[\"isYearEnd\"] = full_calendar_df.pdDate.apply(lambda x: x.is_year_end)\n",
    "full_calendar_df[\"weekOfYear\"] = full_calendar_df.pdDate.apply(lambda x: x.weekofyear)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_str_to_float = lambda x: float(x.replace(\",\",\"\")) if x!=\"-\" else None\n",
    "convert_str_to_date = lambda x, format: datetime.strptime(x, format).date()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Calculate Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_average(data: pd.Series, step_range:int=5, strategy:str=None, **kwargs):\n",
    "    \"\"\"This function calculates moving average of a series\n",
    "    Args:\n",
    "        data (pd.Series): Series if data for evaluation\n",
    "        strategy (str): It can be look_back, look_forward, look_both_sides for calculation of average\n",
    "        step_range (int): Numner of records to be considered for calcuation\"\"\"\n",
    "    values = data.values\n",
    "    response = []\n",
    "    for idx in range(len(values)):\n",
    "        if not kwargs: #Moving Mean\n",
    "            response.append(\n",
    "                np.mean(values[idx:idx+step_range])\n",
    "            )\n",
    "        elif kwargs.get(\"calc_diff_with_mean\"): # x-x_bar\n",
    "            response.append(\n",
    "                values[idx] - np.mean(values[idx:idx+step_range])\n",
    "            )\n",
    "    return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Data frame to Postgres table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def injest_df_to_db(table_name: str, dataframe: pd.DataFrame, if_exists=\"replace\"):\n",
    "    \"\"\"Uploads a dataframe into a table\"\"\"\n",
    "    try:\n",
    "        db = create_engine(CONNECTION_URI)\n",
    "        conn = db.connect()\n",
    "        dataframe.to_sql(table_name, con=conn, if_exists='replace',\n",
    "                index=False)\n",
    "        print(\"Ingest successfull\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed with error: \", str(e))\n",
    "    finally:\n",
    "        if conn:\n",
    "            print(\"Saving and closing.\")\n",
    "            conn.commit()\n",
    "            conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge holiday Calendar\n",
    "  - This will help calculating long weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanse calendar data\n",
    "calendar.Date = calendar[[\"Date\", \"Year\"]].apply(\n",
    "    lambda x: x[0]+\"-\"+str(x[1]), axis=1\n",
    ").apply(\n",
    "    lambda x: convert_str_to_date(x, \"%d-%b-%Y\") if x[0]!=\"-\" else None\n",
    ")\n",
    "\n",
    "calendar_df = pd.merge(\n",
    "    full_calendar_df,\n",
    "    calendar,\n",
    "    how=\"left\",\n",
    "    on=[\"Date\"]\n",
    ")\n",
    "calendar_df.drop(\"Day\", axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save calendar to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingest successfull\n",
      "Saving and closing.\n"
     ]
    }
   ],
   "source": [
    "injest_df_to_db(\"calendar\", calendar_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TODO: Weekend ACs'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar_df[calendar_df.Name == calendar_df.Name]\n",
    "\"TODO: Weekend ACs\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanse experement dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanse experement data\n",
    "exp_data.fillna(method=\"ffill\", inplace=True)\n",
    "exp_data[\"Open\"] = exp_data[\"Open\"].apply(convert_str_to_float)\n",
    "exp_data[\"High\"] = exp_data[\"High\"].apply(convert_str_to_float)\n",
    "exp_data[\"Low\"] = exp_data[\"Low\"].apply(convert_str_to_float)\n",
    "exp_data[\"Close*\"] = exp_data[\"Close*\"].apply(convert_str_to_float)\n",
    "exp_data[\"Date\"] = exp_data[\"Date\"].apply(lambda x: convert_str_to_date(x, \"%b %d, %Y\") if x[0]!=\"-\" else None)\n",
    "exp_data = exp_data.sort_values('Date', ascending=True).reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add statistical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>oneDayChange</th>\n",
       "      <th>oneDayChangePctOver5dAvg</th>\n",
       "      <th>oneDayChangePctOver10dAvg</th>\n",
       "      <th>oneDayChangePctOver15dAvg</th>\n",
       "      <th>oneDayChangePctOver30dAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-08-30</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-08-31</td>\n",
       "      <td>274.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.269220</td>\n",
       "      <td>1.275092</td>\n",
       "      <td>1.279895</td>\n",
       "      <td>1.281738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-09-01</td>\n",
       "      <td>277.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-09-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-09-05</td>\n",
       "      <td>275.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5778</th>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>2046.4</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-1.426899</td>\n",
       "      <td>-1.426899</td>\n",
       "      <td>-1.426899</td>\n",
       "      <td>-1.426899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5779</th>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>2022.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.187296</td>\n",
       "      <td>0.187296</td>\n",
       "      <td>0.187296</td>\n",
       "      <td>0.187296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5780</th>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>2026.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.472674</td>\n",
       "      <td>0.472674</td>\n",
       "      <td>0.472674</td>\n",
       "      <td>0.472674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5781</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>2032.3</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-0.088530</td>\n",
       "      <td>-0.088530</td>\n",
       "      <td>-0.088530</td>\n",
       "      <td>-0.088530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5782</th>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>2034.1</td>\n",
       "      <td>-19.4</td>\n",
       "      <td>-0.953739</td>\n",
       "      <td>-0.953739</td>\n",
       "      <td>-0.953739</td>\n",
       "      <td>-0.953739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5783 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open  oneDayChange  oneDayChangePctOver5dAvg   \n",
       "0     2000-08-30   273.9           0.0                  0.000000  \\\n",
       "1     2000-08-31   274.8           3.5                  1.269220   \n",
       "2     2000-09-01   277.0           0.0                  0.000000   \n",
       "3     2000-09-04     NaN           0.0                  0.000000   \n",
       "4     2000-09-05   275.8           0.0                  0.000000   \n",
       "...          ...     ...           ...                       ...   \n",
       "5778  2023-05-05  2046.4         -29.0                 -1.426899   \n",
       "5779  2023-05-08  2022.5           3.8                  0.187296   \n",
       "5780  2023-05-09  2026.6           9.6                  0.472674   \n",
       "5781  2023-05-10  2032.3          -1.8                 -0.088530   \n",
       "5782  2023-05-11  2034.1         -19.4                 -0.953739   \n",
       "\n",
       "      oneDayChangePctOver10dAvg  oneDayChangePctOver15dAvg   \n",
       "0                      0.000000                   0.000000  \\\n",
       "1                      1.275092                   1.279895   \n",
       "2                      0.000000                   0.000000   \n",
       "3                      0.000000                   0.000000   \n",
       "4                      0.000000                   0.000000   \n",
       "...                         ...                        ...   \n",
       "5778                  -1.426899                  -1.426899   \n",
       "5779                   0.187296                   0.187296   \n",
       "5780                   0.472674                   0.472674   \n",
       "5781                  -0.088530                  -0.088530   \n",
       "5782                  -0.953739                  -0.953739   \n",
       "\n",
       "      oneDayChangePctOver30dAvg  \n",
       "0                      0.000000  \n",
       "1                      1.281738  \n",
       "2                      0.000000  \n",
       "3                      0.000000  \n",
       "4                      0.000000  \n",
       "...                         ...  \n",
       "5778                  -1.426899  \n",
       "5779                   0.187296  \n",
       "5780                   0.472674  \n",
       "5781                  -0.088530  \n",
       "5782                  -0.953739  \n",
       "\n",
       "[5783 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data[\"OpenMovingAvg_5d\"] = exp_data[[\"Open\"]].fillna(method=\"ffill\").apply(lambda x: calculate_moving_average(x, step_range=5))\n",
    "exp_data[\"OpenMovingAvg_10d\"] = exp_data[[\"Open\"]].fillna(method=\"ffill\").apply(lambda x: calculate_moving_average(x, step_range=10))\n",
    "exp_data[\"OpenMovingAvg_15d\"] = exp_data[[\"Open\"]].fillna(method=\"ffill\").apply(lambda x: calculate_moving_average(x, step_range=15))\n",
    "exp_data[\"OpenMovingAvg_30d\"] = exp_data[[\"Open\"]].fillna(method=\"ffill\").apply(lambda x: calculate_moving_average(x, step_range=30))\n",
    "\n",
    "exp_data[\"oneDayChange\"] = (exp_data[\"Close*\"] - exp_data[\"Open\"]).fillna(method=\"ffill\")\n",
    "exp_data[\"oneDayChangePctOver5dAvg\"] = exp_data[\"oneDayChange\"]*100 / exp_data[\"OpenMovingAvg_5d\"]\n",
    "exp_data[\"oneDayChangePctOver10dAvg\"] = exp_data[\"oneDayChange\"]*100 / exp_data[\"OpenMovingAvg_10d\"]\n",
    "exp_data[\"oneDayChangePctOver15dAvg\"] = exp_data[\"oneDayChange\"]*100 / exp_data[\"OpenMovingAvg_15d\"]\n",
    "exp_data[\"oneDayChangePctOver30dAvg\"] = exp_data[\"oneDayChange\"]*100 / exp_data[\"OpenMovingAvg_30d\"]\n",
    "\n",
    "exp_data[\"OpenMovingAvg_5d\"] = exp_data[[\"Open\"]].fillna(method=\"ffill\").apply(lambda x: calculate_moving_average(x, step_range=5, calc_diff_with_mean=True))\n",
    "exp_data[\"OpenMovingAvg_10d\"] = exp_data[[\"Open\"]].fillna(method=\"ffill\").apply(lambda x: calculate_moving_average(x, step_range=10, calc_diff_with_mean=True))\n",
    "exp_data[\"OpenMovingAvg_15d\"] = exp_data[[\"Open\"]].fillna(method=\"ffill\").apply(lambda x: calculate_moving_average(x, step_range=15, calc_diff_with_mean=True))\n",
    "exp_data[\"OpenMovingAvg_30d\"] = exp_data[[\"Open\"]].fillna(method=\"ffill\").apply(lambda x: calculate_moving_average(x, step_range=30, calc_diff_with_mean=True))\n",
    "exp_data[[\"Date\", \"Open\", \"oneDayChange\", \"oneDayChangePctOver5dAvg\", \"oneDayChangePctOver10dAvg\", \"oneDayChangePctOver15dAvg\", \"oneDayChangePctOver30dAvg\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Date', 'Open', 'High', 'Low', 'Close*', 'Adj Close**',\n",
       "       'Volume', 'OpenMovingAvg_5d', 'OpenMovingAvg_10d', 'OpenMovingAvg_15d',\n",
       "       'OpenMovingAvg_30d', 'oneDayChange', 'oneDayChangePctOver5dAvg',\n",
       "       'oneDayChangePctOver10dAvg', 'oneDayChangePctOver15dAvg',\n",
       "       'oneDayChangePctOver30dAvg', 'month', 'year', 'day', 'monthName',\n",
       "       'dayName', 'weekend', 'firstDayOfWeek', 'lastDayOfWeek', 'timeOfMonth',\n",
       "       'pdDate', 'daysInMonth', 'isLeapYear', 'isMonthEnd', 'isMonthStart',\n",
       "       'quarter', 'isQuarterEnd', 'isQuarterStart', 'isYearStart', 'isYearEnd',\n",
       "       'weekOfYear', 'Name', 'Type', 'Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dataset = pd.merge(\n",
    "    exp_data,\n",
    "    calendar_df,\n",
    "    how=\"left\",\n",
    "    on=[\"Date\"]\n",
    ")\n",
    "exp_dataset.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save experement data\n",
    " - In `excel` at `output/exp_dataset.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingest successfull\n",
      "Saving and closing.\n",
      "Ingest successfull\n",
      "Saving and closing.\n"
     ]
    }
   ],
   "source": [
    "exp_dataset.to_excel(\"output/exp_dataset.xlsx\", engine=\"openpyxl\")\n",
    "injest_df_to_db(\"exp_dataset\", exp_dataset)\n",
    "injest_df_to_db(\"exp_data\", exp_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Experements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of holidays\n",
    "  - A1: When `oneDayChange` are noticed `Positive`\n",
    "  - A2: When `oneDayChange` are noticed `Negative`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingest successfull\n",
      "Saving and closing.\n",
      "Ingest successfull\n",
      "Saving and closing.\n"
     ]
    }
   ],
   "source": [
    "# Number of days with +ve change month On month\n",
    "\n",
    "month_template_dict = {\"month\": \"\", \"gains\": 0, \"loss\": 0, \"holidays\": 0}\n",
    "week_template_dict = {\"week\": \"\", \"gains\": 0, \"loss\": 0, \"holidays\": 0}\n",
    "\n",
    "ups_and_downs_month_on_month = defaultdict(lambda : deepcopy(month_template_dict))\n",
    "ups_and_downs_week_on_week = defaultdict(lambda : deepcopy(week_template_dict))\n",
    "\n",
    "def count_ups_and_downs_over_cw_and_month(date: pd.Timestamp, change: float, weekOfYear: int, holiday_name:str):\n",
    "    month_str = date.strftime(\"%Y%m\")\n",
    "    week_str = date.strftime(\"%Y%m\")+str(weekOfYear) if len(str(weekOfYear))==2 else \"0\"+str(weekOfYear)\n",
    "    if change>0:\n",
    "        ups_and_downs_month_on_month[month_str][\"gains\"]+=1\n",
    "        ups_and_downs_month_on_month[month_str][\"month\"] = date.month\n",
    "        ups_and_downs_week_on_week[week_str][\"gains\"]+=1\n",
    "        ups_and_downs_week_on_week[week_str][\"week\"] = weekOfYear\n",
    "    elif change<0:\n",
    "        ups_and_downs_month_on_month[month_str][\"loss\"]+=1\n",
    "        ups_and_downs_month_on_month[month_str][\"month\"] = date.month\n",
    "        ups_and_downs_week_on_week[week_str][\"loss\"]+=1\n",
    "        ups_and_downs_week_on_week[week_str][\"week\"] = weekOfYear\n",
    "\n",
    "    if holiday_name and holiday_name==holiday_name:\n",
    "        ups_and_downs_month_on_month[month_str][\"holidays\"]+=1\n",
    "        ups_and_downs_week_on_week[week_str][\"holidays\"]+=1\n",
    "\n",
    "    \n",
    "exp_dataset[['Date', 'Open', 'oneDayChange', 'oneDayChangePctOver5dAvg',\n",
    "       'oneDayChangePctOver10dAvg', 'Name', 'dayName', 'weekOfYear']][[\"Date\", \"oneDayChange\", \"weekOfYear\", \"Name\"]].apply(\n",
    "              lambda x : count_ups_and_downs_over_cw_and_month(*x), axis=1\n",
    "       )\n",
    "\n",
    "\n",
    "injest_df_to_db(\"ups_and_downs_month_on_month\", pd.DataFrame.from_dict(ups_and_downs_month_on_month, orient=\"index\").reset_index())\n",
    "injest_df_to_db(\"ups_and_downs_week_on_week\", pd.DataFrame.from_dict(ups_and_downs_week_on_week, orient=\"index\").reset_index())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
